{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizerFast, BertConfig, BertForTokenClassification, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:30:10.599504Z","iopub.execute_input":"2022-04-13T17:30:10.599789Z","iopub.status.idle":"2022-04-13T17:30:10.604088Z","shell.execute_reply.started":"2022-04-13T17:30:10.599757Z","shell.execute_reply":"2022-04-13T17:30:10.603409Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"file = open('../input/ner-hindi/hi_train.conll', 'r', encoding = 'utf8').read()\ndataset = file.split('\\n\\n')\ndata = pd.DataFrame(columns = ['sentence', 'word_labels'])\nfor line in dataset:\n    sentences = []\n    ner = []\n    split1 = line.split('\\n')\n    split2 = split1[1:]\n    for each in split2:\n        split3 = each.split('_ _ ')\n        sentences.append(split3[0]), ner.append(split3[1])\n    data.loc[len(data.index)] = [' '.join(sentences), \",\".join(ner)]","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:40:04.754975Z","iopub.execute_input":"2022-04-13T17:40:04.755534Z","iopub.status.idle":"2022-04-13T17:40:34.439791Z","shell.execute_reply.started":"2022-04-13T17:40:04.755490Z","shell.execute_reply":"2022-04-13T17:40:34.439084Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:40:34.441121Z","iopub.execute_input":"2022-04-13T17:40:34.441349Z","iopub.status.idle":"2022-04-13T17:40:34.451021Z","shell.execute_reply.started":"2022-04-13T17:40:34.441317Z","shell.execute_reply":"2022-04-13T17:40:34.450312Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"labels_to_ids = {\n    'B-CORP':1,\n    'B-CW':0,\n    'B-GRP':3,\n    'B-LOC':2,\n    'B-PROD':5,\n    'B-PER':6,\n    'I-CORP':4,\n    'I-CW':7,\n    'I-GRP':8,\n    'I-LOC':9,\n    'I-PROD':10,\n    'I-PER':11,\n    'O':12\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:10.004498Z","iopub.execute_input":"2022-04-13T17:41:10.004764Z","iopub.status.idle":"2022-04-13T17:41:10.009674Z","shell.execute_reply.started":"2022-04-13T17:41:10.004734Z","shell.execute_reply":"2022-04-13T17:41:10.008598Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"ids_to_labels = {}\nfor key, value in labels_to_ids.items():\n    ids_to_labels[value] = key","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:12.186906Z","iopub.execute_input":"2022-04-13T17:41:12.187323Z","iopub.status.idle":"2022-04-13T17:41:12.191798Z","shell.execute_reply.started":"2022-04-13T17:41:12.187286Z","shell.execute_reply":"2022-04-13T17:41:12.190971Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 128\nTRAIN_BATCH_SIZE = 4\nVALID_BATCH_SIZE = 2\nEPOCHS = 1\nLEARNING_RATE = 1e-05\nMAX_GRAD_NORM = 10\ntokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:15.534753Z","iopub.execute_input":"2022-04-13T17:41:15.535461Z","iopub.status.idle":"2022-04-13T17:41:20.763854Z","shell.execute_reply.started":"2022-04-13T17:41:15.535420Z","shell.execute_reply":"2022-04-13T17:41:20.760925Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class dataset(Dataset):\n  def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n  def __getitem__(self, index):\n        # step 1: get the sentence and word labels \n        sentence = self.data.sentence[index].strip().split()  \n        word_labels = self.data.word_labels[index].split(\",\") \n\n        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n        encoding = self.tokenizer(sentence,\n                             is_split_into_words=True,\n                            #  return_offsets_mapping=True, \n                             padding='max_length', \n                             truncation=True, \n                             max_length=self.max_len)\n        # print(sentence)\n        # print(word_labels)\n        encoded_labels = np.ones(MAX_LEN, dtype=int) * -100\n        i = -1\n        for idx, j in enumerate(tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])):\n          # print(j)\n          if j == \"<pad>\":\n            break\n          if j[0] == \"[\":\n            continue\n          if j[0] == \"‚ñÅ\":\n            i += 1\n          try:\n            encoded_labels[idx] = labels_to_ids[word_labels[i]]\n          except:\n            pass\n\n          \n        # print(encoded_labels)\n        \n        # step 3: create token labels only for first word pieces of each tokenized word\n        labels = [labels_to_ids[label] for label in word_labels]\n        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n        # create an empty array of -100 of length max_length\n        # encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n        # print(labels)\n\n\n        # set only labels whose first offset position is 0 and the second is not 0\n        # i = 0\n        # for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n        #   if mapping[0] == 0 and mapping[1] != 0:\n        #     # overwrite label\n        #     encoded_labels[idx] = labels[i]\n        #     i += 1\n\n        # step 4: turn everything into PyTorch tensors\n        # for key, val in encoding.items():\n        #   print({key: torch.as_tensor(val)})\n        item = {key: np.array(val) for key, val in encoding.items()}\n        item['labels'] = np.array(encoded_labels)\n        \n        return item\n\n  def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:24.057515Z","iopub.execute_input":"2022-04-13T17:41:24.060012Z","iopub.status.idle":"2022-04-13T17:41:24.077506Z","shell.execute_reply.started":"2022-04-13T17:41:24.059949Z","shell.execute_reply":"2022-04-13T17:41:24.076495Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ntrain_dataset = data.sample(frac=train_size,random_state=200)\ntest_dataset = data.drop(train_dataset.index).reset_index(drop=True)\ntrain_dataset = train_dataset.reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(data.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = dataset(train_dataset, tokenizer, MAX_LEN)\ntesting_set = dataset(test_dataset, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:25.979960Z","iopub.execute_input":"2022-04-13T17:41:25.980514Z","iopub.status.idle":"2022-04-13T17:41:25.996404Z","shell.execute_reply.started":"2022-04-13T17:41:25.980475Z","shell.execute_reply":"2022-04-13T17:41:25.995692Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"training_set[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:27.880520Z","iopub.execute_input":"2022-04-13T17:41:27.881072Z","iopub.status.idle":"2022-04-13T17:41:27.889910Z","shell.execute_reply.started":"2022-04-13T17:41:27.881015Z","shell.execute_reply":"2022-04-13T17:41:27.889201Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n    print('{0:10}  {1}'.format(token, label))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:29.547625Z","iopub.execute_input":"2022-04-13T17:41:29.547890Z","iopub.status.idle":"2022-04-13T17:41:29.570872Z","shell.execute_reply.started":"2022-04-13T17:41:29.547861Z","shell.execute_reply":"2022-04-13T17:41:29.570189Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:31.271730Z","iopub.execute_input":"2022-04-13T17:41:31.271992Z","iopub.status.idle":"2022-04-13T17:41:31.278821Z","shell.execute_reply.started":"2022-04-13T17:41:31.271962Z","shell.execute_reply":"2022-04-13T17:41:31.278171Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"Preparing Dataset","metadata":{}},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:35.479558Z","iopub.execute_input":"2022-04-13T17:41:35.480111Z","iopub.status.idle":"2022-04-13T17:41:35.484711Z","shell.execute_reply.started":"2022-04-13T17:41:35.480073Z","shell.execute_reply":"2022-04-13T17:41:35.484069Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# from transformers import TFAutoModelForTokenClassification\n\n# model = TFAutoModelForTokenClassification.from_pretrained(\n#     'ai4bharat/indic-bert', num_labels=len(labels_to_ids),from_pt=True\n# )\nmodel = BertForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=len(labels_to_ids))\nmodel.to(device)\n# model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:36.945551Z","iopub.execute_input":"2022-04-13T17:41:36.946101Z","iopub.status.idle":"2022-04-13T17:41:41.974738Z","shell.execute_reply.started":"2022-04-13T17:41:36.946061Z","shell.execute_reply":"2022-04-13T17:41:41.974002Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:51.582401Z","iopub.execute_input":"2022-04-13T17:41:51.582664Z","iopub.status.idle":"2022-04-13T17:41:51.587878Z","shell.execute_reply.started":"2022-04-13T17:41:51.582634Z","shell.execute_reply":"2022-04-13T17:41:51.586942Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Defining the training function on the 80% of the dataset for tuning the bert model\ndef train(epoch):\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    tr_preds, tr_labels = [], []\n    # put model in training mode\n    model.train()\n    \n    for idx, batch in enumerate(training_loader):\n        \n        ids = batch['input_ids'].to(device, dtype = torch.long)\n        mask = batch['attention_mask'].to(device, dtype = torch.long)\n        labels = batch['labels'].to(device, dtype = torch.long)\n\n        loss = model(input_ids=ids, attention_mask=mask, labels=labels)[0]\n        tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)[1]\n#         print(model(input_ids=ids, attention_mask=mask, labels=labels)[0])\n        tr_loss += loss.item()\n\n        nb_tr_steps += 1\n        nb_tr_examples += labels.size(0)\n        \n        if idx % 100==0:\n            loss_step = tr_loss/nb_tr_steps\n            print(f\"Training loss per 100 training steps: {loss_step}\")\n           \n        # compute training accuracy\n        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n        \n        # only compute accuracy at active labels\n        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n        \n        labels = torch.masked_select(flattened_targets, active_accuracy)\n        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n        \n        tr_labels.extend(labels)\n        tr_preds.extend(predictions)\n\n        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n        tr_accuracy += tmp_tr_accuracy\n    \n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(\n            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n        )\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    epoch_loss = tr_loss / nb_tr_steps\n    tr_accuracy = tr_accuracy / nb_tr_steps\n    print(f\"Training loss epoch: {epoch_loss}\")\n    print(f\"Training accuracy epoch: {tr_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:53.130351Z","iopub.execute_input":"2022-04-13T17:41:53.130603Z","iopub.status.idle":"2022-04-13T17:41:53.142238Z","shell.execute_reply.started":"2022-04-13T17:41:53.130575Z","shell.execute_reply":"2022-04-13T17:41:53.141560Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    print(f\"Training epoch: {epoch + 1}\")\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:41:54.629117Z","iopub.execute_input":"2022-04-13T17:41:54.629374Z","iopub.status.idle":"2022-04-13T17:46:06.297979Z","shell.execute_reply.started":"2022-04-13T17:41:54.629345Z","shell.execute_reply":"2022-04-13T17:46:06.296890Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    # put model in evaluation mode\n    model.eval()\n    \n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_examples, nb_eval_steps = 0, 0\n    eval_preds, eval_labels = [], []\n    \n    with torch.no_grad():\n        for idx, batch in enumerate(testing_loader):\n            \n            ids = batch['input_ids'].to(device, dtype = torch.long)\n            mask = batch['attention_mask'].to(device, dtype = torch.long)\n            labels = batch['labels'].to(device, dtype = torch.long)\n            \n            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n            \n            eval_loss += loss.item()\n\n            nb_eval_steps += 1\n            nb_eval_examples += labels.size(0)\n        \n            if idx % 100==0:\n                loss_step = eval_loss/nb_eval_steps\n                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n              \n            # compute evaluation accuracy\n            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n            \n            # only compute accuracy at active labels\n            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        \n            labels = torch.masked_select(flattened_targets, active_accuracy)\n            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n            \n            eval_labels.extend(labels)\n            eval_preds.extend(predictions)\n            \n            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n            eval_accuracy += tmp_eval_accuracy\n\n    labels = [ids_to_labels[id.item()] for id in eval_labels]\n    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n    \n    eval_loss = eval_loss / nb_eval_steps\n    eval_accuracy = eval_accuracy / nb_eval_steps\n    print(f\"Validation Loss: {eval_loss}\")\n    print(f\"Validation Accuracy: {eval_accuracy}\")\n\n    return labels, predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:47:19.309442Z","iopub.execute_input":"2022-04-13T17:47:19.309765Z","iopub.status.idle":"2022-04-13T17:47:19.321608Z","shell.execute_reply.started":"2022-04-13T17:47:19.309730Z","shell.execute_reply":"2022-04-13T17:47:19.320668Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"labels, predictions = valid(model, testing_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:47:20.816719Z","iopub.execute_input":"2022-04-13T17:47:20.817523Z","iopub.status.idle":"2022-04-13T17:47:20.863474Z","shell.execute_reply.started":"2022-04-13T17:47:20.817467Z","shell.execute_reply":"2022-04-13T17:47:20.862697Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from seqeval.metrics import classification_report\n\nlabels = [[i] for i in labels]\npredictions = [[i] for i in predictions]\n# predictions = list(np.expand_dims(predictions, axis = 1))\nprint(classification_report(labels, predictions))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:47:23.424469Z","iopub.execute_input":"2022-04-13T17:47:23.424906Z","iopub.status.idle":"2022-04-13T17:47:23.448760Z","shell.execute_reply.started":"2022-04-13T17:47:23.424869Z","shell.execute_reply":"2022-04-13T17:47:23.447903Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}